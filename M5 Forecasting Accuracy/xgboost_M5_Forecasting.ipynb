{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "YOckP_sYQcda",
    "outputId": "7116d578-e693-4560-d3a1-7e964fb58ebb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ],
   "source": [
    "#run on GoogleDrive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import joblib\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "import os\n",
    "from datetime import timedelta\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "warnings.filterwarnings('ignore')\n",
    "os.chdir('/content/drive/My Drive/m5-forecasting-accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "68mXGwBSqH3H"
   },
   "outputs": [],
   "source": [
    "def convert_obj_to_int(col):\n",
    "    \n",
    "    col = col.astype('category')\n",
    "    col = col.cat.codes.astype('int64')\n",
    "    col -= col.min()\n",
    "    \n",
    "    return col\n",
    "\n",
    "#function used for getting the decimal part of the price\n",
    "def get_last_2_digits(num):\n",
    "    \n",
    "    if str(num) != 'nan':\n",
    "        new_num = num - int(num)\n",
    "    else:\n",
    "        new_num = num\n",
    "        \n",
    "    return new_num\n",
    "\n",
    "#function used for reducing memory usage\n",
    "def memory_reduction(df):\n",
    "    \n",
    "    init_mem = df.memory_usage().sum() / 1024**2 \n",
    "    int_dtypes = [np.int8, np.int16, np.int32, np.int64]\n",
    "    float_dtypes = [np.float16, np.float32, np.float64]\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if str(df[col].dtypes)[0:3] == 'int' or str(df[col].dtypes)[0:5] == 'float':\n",
    "            min_value = df[col].min()\n",
    "            max_value = df[col].max()\n",
    "            if str(df[col].dtypes)[0:3] == 'int':\n",
    "                for i in range(len(int_dtypes)):\n",
    "                    if min_value > np.iinfo(int_dtypes[i]).min and max_value < np.iinfo(int_dtypes[i]).max:\n",
    "                        df[col] = df[col].astype(int_dtypes[i])\n",
    "                        break\n",
    "\n",
    "\n",
    "            else:\n",
    "                for i in range(len(float_dtypes)):\n",
    "                    if min_value > np.finfo(float_dtypes[i]).min and max_value < np.finfo(float_dtypes[i]).max:\n",
    "                        df[col] = df[col].astype(float_dtypes[i])\n",
    "                        break\n",
    "                        \n",
    "\n",
    "    final_mem = df.memory_usage().sum() / 1024 ** 2\n",
    "    pct_reduce = (init_mem - final_mem) / init_mem\n",
    "    print('memory reduced to {:.2f} MB, a reduction of {:.2f}%'.format(final_mem, 100 * pct_reduce))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CmyFY-hLqSqL"
   },
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "    \n",
    "    #load data\n",
    "    price_df = pd.read_csv('sell_prices.csv')\n",
    "    calendar_df = pd.read_csv('calendar.csv')\n",
    "    df = pd.read_csv('sales_train_evaluation.csv')\n",
    "\n",
    "    #get dtype dict of each dataframe\n",
    "    calendar_dtypes = dict(calendar_df.dtypes)\n",
    "    price_dtypes = dict(price_df.dtypes)\n",
    "    df_dtypes = dict(df.dtypes)\n",
    "    \n",
    "    #unifies and changes the dtype of each dataframe\n",
    "    for col in calendar_dtypes.keys():\n",
    "        if calendar_dtypes[col] == 'object' and col not in ['date','d']:\n",
    "            calendar_df[col] = convert_obj_to_int(calendar_df[col])\n",
    "        #converts the dtype of 'date' column to 'datetime' for extracting time features later\n",
    "        elif col == 'date':\n",
    "            calendar_df[col] = pd.to_datetime(calendar_df[col])\n",
    "            \n",
    "    for col in price_dtypes.keys():\n",
    "        if price_dtypes[col] == 'object':\n",
    "            price_df[col] = convert_obj_to_int(price_df[col])\n",
    "\n",
    "    for col in df_dtypes.keys():\n",
    "        if df_dtypes[col] == 'object' and col != 'id':\n",
    "            df[col] = convert_obj_to_int(df[col])\n",
    "        elif str(df_dtypes[col])[0:3] == 'int':\n",
    "            df[col] = df[col].astype('float32')\n",
    "    \n",
    "    #the goal is to predict the sales volume of the next 28 days, make it nan first\n",
    "    last_day = 1941\n",
    "    days_to_predict = 28\n",
    "    for day in range(last_day+1, last_day+days_to_predict+1):\n",
    "        df[f'd_{day}'] = np.nan\n",
    "        \n",
    "    #unpivots df from wide to long format\n",
    "    value_vars = [col for col in df.columns if str(col)[0:2]=='d_']\n",
    "    id_vars = df.columns.difference(value_vars)\n",
    "    df = pd.melt(df, \n",
    "             id_vars = id_vars,\n",
    "             value_vars = value_vars,\n",
    "             var_name = 'd',\n",
    "             value_name = 'sales')\n",
    "    \n",
    "    #merges df, calendar_df, price_df together\n",
    "    df = pd.merge(df, calendar_df, how='left', on='d')\n",
    "    df = pd.merge(df, price_df, how='left', on=['store_id', 'item_id', 'wm_yr_wk'])\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "8wQrEtLeqZ40",
    "outputId": "02e33df5-d8e1-4399-e9b2-648aeef94b60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "memory reduced to 3206.20 MB, a reduction of 69.57%\n",
      "CPU times: user 2min 26s, sys: 6.43 s, total: 2min 32s\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = preprocess_data()\n",
    "df = memory_reduction(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "id": "DYAevwS9a6vO",
    "outputId": "4227b655-b3bd-4f74-d493-9706e74bcd82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cat_id', 'dept_id', 'id', 'item_id', 'state_id', 'store_id', 'd',\n",
       "       'sales', 'date', 'wm_yr_wk', 'weekday', 'wday', 'month', 'year',\n",
       "       'event_name_1', 'event_type_1', 'event_name_2', 'event_type_2',\n",
       "       'snap_CA', 'snap_TX', 'snap_WI', 'sell_price'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xXQ708slFe9M"
   },
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \n",
    "    # id-wise simple shift features\n",
    "    shift_params = [7, 14, 21, 28, 35]\n",
    "    for s in shift_params:\n",
    "        df[f'feature_lag_t{s}'] = df.groupby(['id'])['sales'].apply(lambda x:x.shift(s)).astype('float16')\n",
    "    print('part 1 completed!')\n",
    "\n",
    "    # id-wise shift rolling mean and std features\n",
    "    rolling_params = [7, 14, 30, 45]\n",
    "    for s in shift_params:\n",
    "        for r in rolling_params:\n",
    "            df['rolling_mean'+str(r)+'_shift'+str(s)] = df.groupby(['id'])['sales'].apply(lambda x: x.shift(s).rolling(r).mean()).astype('float16')\n",
    "            df['rolling_std'+str(r)+'_shift'+str(s)] = df.groupby(['id'])['sales'].apply(lambda x: x.shift(s).rolling(r).std()).astype('float16')\n",
    "    df = df[(df['date'] >= '2016-04-22') | (pd.notna(df['rolling_mean45_shift35']))]\n",
    "    print('part 2 completed!')\n",
    "\n",
    "    # store-wise mean and std features\n",
    "    df['store_id_mean'] = df.groupby(['store_id'])['sales'].transform('mean').astype('float16')\n",
    "    df['store_id_std'] = df.groupby(['store_id'])['sales'].transform('std').astype('float16')\n",
    "    print('part 3 completed!')\n",
    "\n",
    "    # item_id-wise mean and std features\n",
    "    df['item_id_mean'] = df.groupby(['item_id'])['sales'].transform('mean').astype('float16')\n",
    "    df['item_id_std'] = df.groupby(['item_id'])['sales'].transform('std').astype('float16')\n",
    "    print('part 4 completed!')\n",
    "\n",
    "    # time features\n",
    "    df['day_week'] = getattr(df['date'].dt, 'dayofweek').astype('int8')\n",
    "    df['day_month'] = getattr(df['date'].dt, 'day').astype('int8')\n",
    "    df['week_month'] = df['day_month'].apply(lambda x: math.ceil(x/7)).astype('int8')\n",
    "    df['week_year'] = getattr(df['date'].dt, 'weekofyear').astype('int8')\n",
    "    df['month'] = getattr(df['date'].dt, 'month').astype('int8')\n",
    "    df['quarter'] = getattr(df['date'].dt, 'quarter').astype('int8')\n",
    "    df['year'] = getattr(df['date'].dt, 'year').astype('int16')\n",
    "    df['year'] = (df['year']-df['year'].min()).astype('int8')\n",
    "    df['if_weekend'] = (df['day_week'] >= 5).astype('int8')\n",
    "    print('part 5 completed!')\n",
    "    \n",
    "    # price features\n",
    "    price_params = ['max','min','median','mean','std']\n",
    "    for p in price_params:\n",
    "        df[f'price_{p}'] = df.groupby(['id'])['sell_price'].transform(p)\n",
    "    df['price_momentum_day'] = df['sell_price'] / df.groupby(['id'])['sell_price'].apply(lambda x:x.shift(1))\n",
    "    df['price_momentum_week'] = df['sell_price'] / df.groupby(['id'])['sell_price'].apply(lambda x:x.shift(7))\n",
    "    df['price_momentum_month'] = df['sell_price'] / df.groupby(['id','month'])['sell_price'].transform('mean')\n",
    "    df['price_momentum_year'] = df['sell_price'] / df.groupby(['id','year'])['sell_price'].transform('mean')\n",
    "    df['price_last_2_digits'] = df['sell_price'].apply(lambda x: get_last_2_digits(x))\n",
    "    print('part 6 completed!')\n",
    "\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "HLOGwSUgWz2j",
    "outputId": "f00d960b-f593-467c-c193-1831f49839f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "part 1 completed!\n",
      "part 2 completed!\n",
      "part 3 completed!\n",
      "part 4 completed!\n",
      "part 5 completed!\n",
      "part 6 completed!\n",
      "CPU times: user 33min 1s, sys: 22.2 s, total: 33min 23s\n",
      "Wall time: 33min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = create_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "oTqVq3NkWHjA",
    "outputId": "e4b528a5-c3d0-4d8e-c749-ca21b6c2811f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_id</th>\n",
       "      <th>dept_id</th>\n",
       "      <th>id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>state_id</th>\n",
       "      <th>store_id</th>\n",
       "      <th>d</th>\n",
       "      <th>sales</th>\n",
       "      <th>date</th>\n",
       "      <th>wm_yr_wk</th>\n",
       "      <th>weekday</th>\n",
       "      <th>wday</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>event_name_1</th>\n",
       "      <th>event_type_1</th>\n",
       "      <th>event_name_2</th>\n",
       "      <th>event_type_2</th>\n",
       "      <th>snap_CA</th>\n",
       "      <th>snap_TX</th>\n",
       "      <th>snap_WI</th>\n",
       "      <th>sell_price</th>\n",
       "      <th>feature_lag_t7</th>\n",
       "      <th>feature_lag_t14</th>\n",
       "      <th>feature_lag_t21</th>\n",
       "      <th>feature_lag_t28</th>\n",
       "      <th>feature_lag_t35</th>\n",
       "      <th>rolling_mean7_shift7</th>\n",
       "      <th>rolling_std7_shift7</th>\n",
       "      <th>rolling_mean14_shift7</th>\n",
       "      <th>rolling_std14_shift7</th>\n",
       "      <th>rolling_mean30_shift7</th>\n",
       "      <th>rolling_std30_shift7</th>\n",
       "      <th>rolling_mean45_shift7</th>\n",
       "      <th>rolling_std45_shift7</th>\n",
       "      <th>rolling_mean7_shift14</th>\n",
       "      <th>rolling_std7_shift14</th>\n",
       "      <th>rolling_mean14_shift14</th>\n",
       "      <th>rolling_std14_shift14</th>\n",
       "      <th>rolling_mean30_shift14</th>\n",
       "      <th>...</th>\n",
       "      <th>rolling_mean30_shift21</th>\n",
       "      <th>rolling_std30_shift21</th>\n",
       "      <th>rolling_mean45_shift21</th>\n",
       "      <th>rolling_std45_shift21</th>\n",
       "      <th>rolling_mean7_shift28</th>\n",
       "      <th>rolling_std7_shift28</th>\n",
       "      <th>rolling_mean14_shift28</th>\n",
       "      <th>rolling_std14_shift28</th>\n",
       "      <th>rolling_mean30_shift28</th>\n",
       "      <th>rolling_std30_shift28</th>\n",
       "      <th>rolling_mean45_shift28</th>\n",
       "      <th>rolling_std45_shift28</th>\n",
       "      <th>rolling_mean7_shift35</th>\n",
       "      <th>rolling_std7_shift35</th>\n",
       "      <th>rolling_mean14_shift35</th>\n",
       "      <th>rolling_std14_shift35</th>\n",
       "      <th>rolling_mean30_shift35</th>\n",
       "      <th>rolling_std30_shift35</th>\n",
       "      <th>rolling_mean45_shift35</th>\n",
       "      <th>rolling_std45_shift35</th>\n",
       "      <th>store_id_mean</th>\n",
       "      <th>store_id_std</th>\n",
       "      <th>item_id_mean</th>\n",
       "      <th>item_id_std</th>\n",
       "      <th>day_week</th>\n",
       "      <th>day_month</th>\n",
       "      <th>week_month</th>\n",
       "      <th>week_year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>if_weekend</th>\n",
       "      <th>price_max</th>\n",
       "      <th>price_min</th>\n",
       "      <th>price_median</th>\n",
       "      <th>price_mean</th>\n",
       "      <th>price_std</th>\n",
       "      <th>price_momentum_day</th>\n",
       "      <th>price_momentum_week</th>\n",
       "      <th>price_momentum_month</th>\n",
       "      <th>price_momentum_year</th>\n",
       "      <th>price_last_2_digits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60034805</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>FOODS_3_823_WI_3_evaluation</td>\n",
       "      <td>1432</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.980469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.571289</td>\n",
       "      <td>0.534668</td>\n",
       "      <td>0.643066</td>\n",
       "      <td>0.841797</td>\n",
       "      <td>0.633301</td>\n",
       "      <td>0.808594</td>\n",
       "      <td>0.533203</td>\n",
       "      <td>0.786133</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>1.112305</td>\n",
       "      <td>0.714355</td>\n",
       "      <td>0.914062</td>\n",
       "      <td>0.533203</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>0.444336</td>\n",
       "      <td>0.785156</td>\n",
       "      <td>1.105469</td>\n",
       "      <td>4.039062</td>\n",
       "      <td>0.783203</td>\n",
       "      <td>1.667969</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.980469</td>\n",
       "      <td>2.480469</td>\n",
       "      <td>2.880859</td>\n",
       "      <td>2.814453</td>\n",
       "      <td>0.163468</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.030273</td>\n",
       "      <td>1.024414</td>\n",
       "      <td>0.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60034806</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>FOODS_3_824_WI_3_evaluation</td>\n",
       "      <td>1433</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.480469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.285645</td>\n",
       "      <td>0.488037</td>\n",
       "      <td>0.142822</td>\n",
       "      <td>0.363037</td>\n",
       "      <td>0.300049</td>\n",
       "      <td>0.535156</td>\n",
       "      <td>0.288818</td>\n",
       "      <td>0.505371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.214233</td>\n",
       "      <td>0.579102</td>\n",
       "      <td>0.233276</td>\n",
       "      <td>0.503906</td>\n",
       "      <td>0.333252</td>\n",
       "      <td>0.563965</td>\n",
       "      <td>1.105469</td>\n",
       "      <td>4.039062</td>\n",
       "      <td>0.421143</td>\n",
       "      <td>0.933594</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.679688</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.679688</td>\n",
       "      <td>2.509766</td>\n",
       "      <td>0.258118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991211</td>\n",
       "      <td>1.116211</td>\n",
       "      <td>0.480469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60034807</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>FOODS_3_825_WI_3_evaluation</td>\n",
       "      <td>1434</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.980469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.856934</td>\n",
       "      <td>0.899902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.109375</td>\n",
       "      <td>0.766602</td>\n",
       "      <td>0.897461</td>\n",
       "      <td>0.822266</td>\n",
       "      <td>1.006836</td>\n",
       "      <td>1.142578</td>\n",
       "      <td>1.344727</td>\n",
       "      <td>0.785645</td>\n",
       "      <td>1.050781</td>\n",
       "      <td>0.700195</td>\n",
       "      <td>0.876953</td>\n",
       "      <td>0.888672</td>\n",
       "      <td>1.091797</td>\n",
       "      <td>1.105469</td>\n",
       "      <td>4.039062</td>\n",
       "      <td>0.688477</td>\n",
       "      <td>1.145508</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4.378906</td>\n",
       "      <td>3.980469</td>\n",
       "      <td>3.980469</td>\n",
       "      <td>4.121094</td>\n",
       "      <td>0.190039</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.957520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60034808</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>FOODS_3_826_WI_3_evaluation</td>\n",
       "      <td>1435</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.857422</td>\n",
       "      <td>2.267578</td>\n",
       "      <td>1.428711</td>\n",
       "      <td>1.650391</td>\n",
       "      <td>1.366211</td>\n",
       "      <td>1.299805</td>\n",
       "      <td>1.200195</td>\n",
       "      <td>1.235352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.577148</td>\n",
       "      <td>1.142578</td>\n",
       "      <td>0.663086</td>\n",
       "      <td>1.099609</td>\n",
       "      <td>0.922852</td>\n",
       "      <td>1.044922</td>\n",
       "      <td>0.903320</td>\n",
       "      <td>1.105469</td>\n",
       "      <td>4.039062</td>\n",
       "      <td>0.673828</td>\n",
       "      <td>1.271484</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>1.280273</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.280273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60034809</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>FOODS_3_827_WI_3_evaluation</td>\n",
       "      <td>1436</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>d_1969</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-06-19</td>\n",
       "      <td>11621</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.714844</td>\n",
       "      <td>1.975586</td>\n",
       "      <td>1.642578</td>\n",
       "      <td>1.823242</td>\n",
       "      <td>1.166992</td>\n",
       "      <td>1.463867</td>\n",
       "      <td>0.799805</td>\n",
       "      <td>1.307617</td>\n",
       "      <td>0.571289</td>\n",
       "      <td>0.786621</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.960938</td>\n",
       "      <td>0.533203</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>0.688965</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>1.105469</td>\n",
       "      <td>4.039062</td>\n",
       "      <td>0.651855</td>\n",
       "      <td>2.099609</td>\n",
       "      <td>6</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          cat_id  dept_id  ... price_momentum_year  price_last_2_digits\n",
       "60034805       0        2  ...            1.024414             0.980469\n",
       "60034806       0        2  ...            1.116211             0.480469\n",
       "60034807       0        2  ...            1.000000             0.980469\n",
       "60034808       0        2  ...            1.000000             0.280273\n",
       "60034809       0        2  ...            1.000000             0.000000\n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdecfIcI-SVt"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "0pRVWv_N7WLk"
   },
   "outputs": [],
   "source": [
    "features_to_exclude = ['id','sales','date','d','weekday','wm_yr_wk','state_id','store_id','event_name_1','event_type_1','event_name_2','event_type_2']\n",
    "features_to_use = [i for i in df.columns if i not in features_to_exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "qUVTB6HW-K26"
   },
   "outputs": [],
   "source": [
    "def xgb_model(store_id, df):\n",
    "\n",
    "    df = df[df['store_id'] == store_id]\n",
    "    X_train = df[df['date'] <= '2016-04-22']\n",
    "    Y_train = X_train['sales']\n",
    "    X_valid = df[(df['date'] > '2016-04-22') & (df['date'] <= '2016-05-22')]\n",
    "    Y_valid = X_valid['sales']\n",
    "    \n",
    "    train_set = xgb.DMatrix(X_train[features_to_use],label=Y_train)\n",
    "    valid_set = xgb.DMatrix(X_valid[features_to_use],label=Y_valid)\n",
    "    watch_list = [(train_set, 'train'), (valid_set, 'valid')]\n",
    "    param = {'max_depth' : 6, \n",
    "             'eta' : 0.047, \n",
    "             'silent' : 1, \n",
    "             'objective': 'reg:linear',\n",
    "             'subsample': 0.8,\n",
    "             'colsample_bytree' : 0.5, \n",
    "             'min_child_weight' : 7,\n",
    "             'verbose_eval' : 20}\n",
    "    model = xgb.train(param, train_set, num_boost_round=500, early_stopping_rounds=20, evals=watch_list)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzKggpI2GvS3"
   },
   "outputs": [],
   "source": [
    "def lgb_model(store_id, df):\n",
    "\n",
    "    df = df[df['store_id'] == store_id]\n",
    "    X_train = df[df['date'] <= '2016-04-22']\n",
    "    Y_train = X_train['sales']\n",
    "    X_valid = df[(df['date'] > '2016-04-22') & (df['date'] <= '2016-05-22')]\n",
    "    Y_valid = X_valid['sales']\n",
    "\n",
    "    cat_featuress = ['item_id', 'dept_id', 'cat_id'] + [\"event_name_1\", \"event_name_2\", \"event_type_1\", \"event_type_2\"] + ['snap_CA', 'snap_WI', 'snap_TX']\n",
    "\n",
    "    train_set = lgb.Dataset(X_train[features_to_use], \n",
    "                            Y_train, \n",
    "                            categorical_feature = cat_features, \n",
    "                            free_raw_data = False)\n",
    "    valid_set = lgb.Dataset(X_valid[features_to_use], \n",
    "                            Y_valid, \n",
    "                            categorical_feature = cat_features, \n",
    "                            free_raw_data = False)\n",
    "    params = {\n",
    "          'boosting_type': 'gbdt',\n",
    "          'objective': 'tweedie',\n",
    "          'tweedie_variance_power': 1.1,\n",
    "          'metric': 'rmse',\n",
    "          'subsample': 0.85,\n",
    "          'subsample_freq': 1,\n",
    "          'learning_rate': 0.03,\n",
    "          'num_leaves': 2**11-1,\n",
    "          'min_data_in_leaf': 2**12-1,\n",
    "          'feature_fraction': 0.6,\n",
    "          'max_bin': 100,\n",
    "          'boost_from_average': False,\n",
    "          'verbose': -1,\n",
    "          'seed': 42}\n",
    "    \n",
    "    model = lgb.train(params, train_set, num_boost_round=100, early_stopping_rounds=100, valid_sets = [train_set, valid_set], verbose_eval=100)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "NV_wSwMU-Mmo",
    "outputId": "47c3897c-3f83-4947-e8ba-e1a8628b3ad9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('model',i+1)\n",
    "    model_name = 'model' + str(i) + '.sav' \n",
    "    model = xgb_model(i, df)\n",
    "    joblib.dump(model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "l8qQf5n3Ok5f",
    "outputId": "49983104-2d9d-41a8-ebfe-f0103ed48eb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30490"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_features(df):\n",
    "    df['feature_lag_t7'] = df.groupby(['id'])['sales'].apply(lambda x:x.shift(7)).astype('float16')\n",
    "    df['feature_lag_t14'] = df.groupby(['id'])['sales'].apply(lambda x:x.shift(14)).astype('float16')\n",
    "    df['feature_lag_t21'] = df.groupby(['id'])['sales'].apply(lambda x:x.shift(21)).astype('float16')\n",
    "\n",
    "    new_shift_params =[7, 14, 21]\n",
    "    new_rolling_params = [7, 14, 30, 45]\n",
    "\n",
    "    for s in new_shift_params:\n",
    "        for r in new_rolling_params:\n",
    "            df['rolling_mean'+str(r)+'_shift'+str(s)] = df.groupby(['id'])['sales'].apply(lambda x: x.shift(s).rolling(r).mean()).astype('float16')\n",
    "            df['rolling_std'+str(r)+'_shift'+str(s)] = df.groupby(['id'])['sales'].apply(lambda x: x.shift(s).rolling(r).std()).astype('float16')\n",
    "\n",
    "    return df\n",
    "\n",
    "#predict the sales using the model\n",
    "def make_predictions(df, model, store_id):\n",
    "    df = df[df['store_id'] == store_id]\n",
    "    test_set_week1 = df[(df['date'] > '2016-05-22') & (df['date'] <= '2016-05-29')] \n",
    "    df.loc[(df['date'] > '2016-05-22') & (df['date'] <= '2016-05-29'), 'sales'] = model.predict(test_set_week1[features_to_use])\n",
    "\n",
    "    df = add_features(df)\n",
    "    test_set_week2 = df[(df['date'] > '2016-05-29') & (df['date'] <= '2016-06-25')] \n",
    "    df.loc[(df['date'] > '2016-05-29') & (df['date'] <= '2016-06-05'), 'sales'] = model.predict(test_set_week2[features_to_use])\n",
    "\n",
    "    df = add_features(df)\n",
    "    test_set_week3 = df[(df['date'] > '2016-06-05') & (df['date'] <= '2016-06-12')] \n",
    "    df.loc[(df['date'] > '2016-06-05') & (df['date'] <= '2016-06-12'), 'sales'] = model.predict(test_set_week3[features_to_use])\n",
    "\n",
    "    df = add_features(df)\n",
    "    test_set_week4 = df[(df['date'] > '2016-06-12') & (df['date'] <= '2016-06-19')] \n",
    "    df.loc[(df['date'] > '2016-06-12') & (df['date'] <= '2016-06-19'), 'sales'] = model.predict(test_set_week4[features_to_use])\n",
    "\n",
    "    return df[(df['date'] > '2016-05-22') & (df['date'] <= '2016-06-19')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zgs-_y4Ma9qH"
   },
   "outputs": [],
   "source": [
    "for i in range(1, 10+1):\n",
    "    model_name = 'model' + str(i) + '.sav'\n",
    "    model = joblib.load(model_name)\n",
    "\n",
    "    if i == 1:\n",
    "        result = make_predictions(df, model, i)\n",
    "    else:\n",
    "        result = pd.concat([result, make_predictions(df, model, i)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "jPnxiTP4gpVR"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "#regressor = xgb.XGBRegressor(n_estimators=20, max_depth=6, subsample=0.8, learning_rate=0.04, min_child_weight=3)\n",
    "regressor = xgb.XGBRegressor(n_estimators=30, max_depth=6, learning_rate=0.047, min_child_weight=7, subsample=0.8)\n",
    "param = {'colsample_bytree' : [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]}\n",
    "\n",
    "#n_iter, int, default=10\n",
    "#Number of parameter settings that are sampled. n_iter trades off runtime vs quality of the solution.\n",
    "grid = RandomizedSearchCV(regressor, \n",
    "                          param, \n",
    "                          cv=3, \n",
    "                          scoring='neg_root_mean_squared_error', \n",
    "                          n_iter=6,\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "gJlAB9-jz9UE",
    "outputId": "030499cd-b234-41aa-d14d-f6037de3c7f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:09:24] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:10:36] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:11:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:13:02] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:14:25] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:15:49] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:17:12] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:18:47] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:20:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:21:58] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:23:43] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:25:29] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:27:15] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:29:11] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:31:09] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:33:07] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:35:13] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[12:37:22] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  18 out of  18 | elapsed: 30.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:39:31] WARNING: /workspace/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32min 25s, sys: 642 ms, total: 32min 26s\n",
      "Wall time: 32min 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df0 = df[df['store_id']==0]\n",
    "X_train = df0[(df0['date'] <= '2016-04-22') & (df0['date'] >= '2015-04-22')]\n",
    "Y_train = X_train['sales']\n",
    "tqdm(grid.fit(X_train[features_to_use], Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "eMrIBfvtYDIO",
    "outputId": "5b2c17c1-d30a-4572-9af5-2741c9f800aa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.5}"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "jLF5VSOTq4Ol",
    "outputId": "0b754c6e-54ba-4fbf-f468-cd8a916c28a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 71.91131719,  82.32553109,  94.33311383, 104.37431343,\n",
       "        116.46956921, 126.49758959]),\n",
       " 'mean_score_time': array([1.0800763 , 1.05936877, 1.05722809, 1.06534958, 1.06478715,\n",
       "        1.058484  ]),\n",
       " 'mean_test_score': array([-2.34680851, -2.34304396, -2.34305406, -2.3453606 , -2.34386269,\n",
       "        -2.34347248]),\n",
       " 'param_colsample_bytree': masked_array(data=[0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
       "              mask=[False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'colsample_bytree': 0.4},\n",
       "  {'colsample_bytree': 0.5},\n",
       "  {'colsample_bytree': 0.6},\n",
       "  {'colsample_bytree': 0.7},\n",
       "  {'colsample_bytree': 0.8},\n",
       "  {'colsample_bytree': 0.9}],\n",
       " 'rank_test_score': array([6, 1, 2, 5, 4, 3], dtype=int32),\n",
       " 'split0_test_score': array([-2.48316026, -2.47757459, -2.48291469, -2.47325206, -2.4756701 ,\n",
       "        -2.47603512]),\n",
       " 'split1_test_score': array([-2.33144665, -2.32621503, -2.32586908, -2.34050035, -2.33135986,\n",
       "        -2.33263135]),\n",
       " 'split2_test_score': array([-2.22581863, -2.22534227, -2.2203784 , -2.22232938, -2.22455812,\n",
       "        -2.22175097]),\n",
       " 'std_fit_time': array([0.11748282, 0.167092  , 0.66666551, 0.6719193 , 1.19469897,\n",
       "        1.12577972]),\n",
       " 'std_score_time': array([0.03415366, 0.00792487, 0.01470554, 0.02488877, 0.02467951,\n",
       "        0.00966916]),\n",
       " 'std_test_score': array([0.10561934, 0.10365872, 0.10786664, 0.10249639, 0.10289654,\n",
       "        0.10409372])}"
      ]
     },
     "execution_count": 35,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6JdkIZcDxLw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "xgboost_M5",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
